{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import pandas as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        try:\n",
    "            yield eval(l)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for d in readGz(\"renttherunway_final_data.json.gz\"):\n",
    "    dataset.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192462"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heightConversion(h):\n",
    "    ft, inch = h.split('\\' ')\n",
    "    ft = int(ft)\n",
    "    inch = int(inch.replace('\\\"', ''))\n",
    "    return ft * 12 + inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = []\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "for d in dataset:\n",
    "    feature_needed = ['weight', 'height', 'fit', 'size', 'body type', 'review_text', 'review_summary', 'rating']\n",
    "    keys = list(d.keys())\n",
    "    if all([i in keys for i in feature_needed]):\n",
    "        d['weight'] = int(d['weight'].replace(\"lbs\", \"\"))\n",
    "        d['height'] = heightConversion(d['height'])\n",
    "        new_dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153441"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['fit'] for d in new_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain, data_vt, ytrain, y_vt = train_test_split(new_dataset, y, test_size=0.3, random_state=42)\n",
    "dataValid, dataTest, yvalid, ytest = train_test_split(data_vt, y_vt, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [[1, d['weight'], d['height'], d['size']] for d in dataTrain]\n",
    "Xvalid = [[1, d['weight'], d['height'], d['size']] for d in dataValid]\n",
    "Xtest = [[1, d['weight'], d['height'], d['size']] for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, y):\n",
    "    correct = pred == y\n",
    "    return sum(correct)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0001, accuracy is 0.7334028501911714.\n",
      "C = 0.001, accuracy is 0.7330118178658325.\n",
      "C = 0.01, accuracy is 0.7330118178658325.\n",
      "C = 0.1, accuracy is 0.7330552659019812.\n",
      "C = 1, accuracy is 0.7330552659019812.\n",
      "C = 10, accuracy is 0.7330552659019812.\n",
      "C = 100, accuracy is 0.7330552659019812.\n",
      "C = 1000, accuracy is 0.7330552659019812.\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model - using only weight, height and size\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "mods = {}\n",
    "accs = {}\n",
    "accura = []\n",
    "for i in Cs:\n",
    "    baselineMod = linear_model.LogisticRegression(C=i, solver='newton-cg')\n",
    "    baselineMod.fit(Xtrain,ytrain)\n",
    "    blPred = baselineMod.predict(Xvalid)\n",
    "    blacc = accuracy(blPred, yvalid)\n",
    "    mods[i] = baselineMod\n",
    "    accs[i] = blacc\n",
    "    accura.append(blacc)\n",
    "    print(\"C = {}, accuracy is {}.\".format(str(i), str(blacc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7334028501911714"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['fit'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134723, 28869, 28870)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain, data_vt, ytrain, y_vt = train_test_split(dataset, y, test_size=0.3, random_state=42)\n",
    "dataValid, dataTest, yvalid, ytest = train_test_split(data_vt, y_vt, test_size=0.5, random_state=42)\n",
    "len(dataTrain), len(dataValid), len(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32111"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "sw = stopwords.words(\"English\")\n",
    "for d in dataTrain:\n",
    "    r = ''.join([c for c in d['review_text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        w = stemmer.stem(w)\n",
    "        wordCount[w] += 1\n",
    "\n",
    "len(wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31996"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = [(wordCount[w],w) for w in wordCount if w not in sw]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x[1] for x in counts[:5000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rating = float('-inf')\n",
    "min_rating = float('inf')\n",
    "for d in dataset:\n",
    "    max_rating = max(int(d['rating']), max_rating)\n",
    "    min_rating = min(int(d['rating']), min_rating)\n",
    "max_rating, min_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(d): \n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in d['review_text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        w = stemmer.stem(w)\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat2 = [0]*(max_rating-min_rating+1)\n",
    "    feat2[max_rating-int(d['rating'])] = 1\n",
    "    return [1] + feat + feat2[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [feature(d) for d in dataTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvalid = [feature(d) for d in dataValid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest= [feature(d) for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(C=1)\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8023831791887491"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictValid = model.predict(Xvalid)\n",
    "accValid = accuracy(predictValid, yvalid)\n",
    "accValid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7934534118462071"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictTest = model.predict(Xtest)\n",
    "accTest = accuracy(predictTest, ytest)\n",
    "accTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.814820038152357"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictTrain = model.predict(Xtrain)\n",
    "accTrain = accuracy(predictTrain, ytrain)\n",
    "accTrain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
